{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect results\n",
    "\n",
    "In this notebook, I check if I can collect all the results in a decent manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "\n",
    "from os.path import dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom\n",
    "\n",
    "root_dir = dirname(dirname(os.getcwd()))\n",
    "src_dir = os.path.join(root_dir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "import exp\n",
    "from exp.utils.extra import mem_usage\n",
    "from exp.runner.RunExp import RunExp\n",
    "from exp.runner.RunMercs import RunMercs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_or_make_runner(idx=None, kind='RunExp', root_dir=None, **kwargs):\n",
    "    \n",
    "    if kind in {'RunExp'}:\n",
    "        helper = RunExp()\n",
    "    elif kind in {'RunMercs'}:\n",
    "        helper = RunMercs()\n",
    "    else:\n",
    "        msg = \"\"\"\n",
    "        Did not recognize kind:    {}\n",
    "        \"\"\".format(kind)\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    helper.make_config(idx=idx, root_dir=root_dir, **kwargs)\n",
    "    runner_fname = helper.get_fname(kind)\n",
    "\n",
    "    if os.path.isfile(runner_fname):\n",
    "        with open(runner_fname, 'rb') as f:\n",
    "            runner = pkl.load(f)\n",
    "        del helper\n",
    "    else:\n",
    "        msg = \"\"\"\n",
    "        Could not load the actual runner. Using the self-made helper.\n",
    "        \"\"\"\n",
    "        warninngs.warn(msg)\n",
    "        runner = helper\n",
    "    return runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def examine_RunExp(runner):\n",
    "    \n",
    "    # child\n",
    "    child = runner.config['child']\n",
    "    \n",
    "    # folds\n",
    "    folds = runner.config[child]['folds']\n",
    "    \n",
    "    # idxs\n",
    "    exploration_fname = runner.get_fname('exploration')\n",
    "    with open(exploration_fname, 'r') as f:\n",
    "        exploration = json.load(f)\n",
    "        \n",
    "    idxs = exploration['idx']\n",
    "    return child, folds, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_multindex(df, idx, f_idx):\n",
    "    \"\"\"\n",
    "    Add multi-index correctly.\n",
    "    \"\"\"\n",
    "    df['idx'] = idx\n",
    "    df['f_idx'] = f_idx\n",
    "    \n",
    "    if 'q_idx' in df.columns:\n",
    "        df = df.set_index(['idx', 'f_idx', 'q_idx'])\n",
    "    else:\n",
    "        df = df.set_index(['idx', 'f_idx'])\n",
    "    return df\n",
    "\n",
    "def extract_unique_fnames_kind(df, kind=None):\n",
    "    \"\"\"\n",
    "    Extract unique fnames from df of outputs.\n",
    "    \n",
    "    This allows us to read every file just once.\n",
    "    \"\"\"\n",
    "    column = [c for c in df.columns if kind in c][0]\n",
    "    uniq_fnames = df[column].unique()\n",
    "    return column, uniq_fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All things queries\n",
    "def count_attributes(q_codes, encoding):\n",
    "    \"\"\"\n",
    "    Count the number of appearances of a certain value, row-wise.\n",
    "    \"\"\"\n",
    "    return np.count_nonzero(q_codes==encoding, axis=1)\n",
    "\n",
    "def extract_attributes(q_codes, encoding):\n",
    "    \"\"\"\n",
    "    Extract the attributes that fulfill a certain role, row-wise.\n",
    "    \"\"\"\n",
    "    nb_queries = q_codes.shape[0]\n",
    "    encod_atts = np.transpose(np.nonzero(q_codes==encoding))\n",
    "    \n",
    "    d = [[] for row in range(nb_queries)]\n",
    "    for qry_idx, att_idx in encod_atts:\n",
    "        d[qry_idx].append(att_idx)\n",
    "        \n",
    "    d = [tuple(l) for l in d]\n",
    "    return d\n",
    "\n",
    "def transform_q_codes(q_codes):\n",
    "    \n",
    "    # TODO: Extract the encoding from somewhere\n",
    "    df = pd.DataFrame()\n",
    "    targ_encoding = 1\n",
    "    miss_encoding = -1\n",
    "    nb_qrys, nb_atts = q_codes.shape\n",
    "    \n",
    "    df['targ'] = extract_attributes(q_codes, targ_encoding)\n",
    "    df['perc_miss'] = count_attributes(q_codes, miss_encoding)/nb_atts\n",
    "    df['q_idx'] = np.arange(nb_qrys)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All things config\n",
    "def transform_cfg(cfg):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # Prelims\n",
    "    child = cfg['child']\n",
    "    dataset = cfg['dataset']\n",
    "    mod_cfg = cfg[child]\n",
    "    \n",
    "    # Actual transformation\n",
    "    head_tuple = ('dataset', *mod_cfg.keys())\n",
    "    data_tuple = (dataset, *mod_cfg.values())\n",
    "    \n",
    "    df = pd.DataFrame.from_records([data_tuple], columns=head_tuple)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     23
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General methods\n",
    "\n",
    "def aggregate_outputs(df_fns, kind='results'):\n",
    "    \"\"\"\n",
    "    Collect in such a way that no single file is accessed more than once.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    column, uniq_fnames = extract_unique_fnames_kind(df_fns, kind=kind)\n",
    "        \n",
    "    for fn in uniq_fnames:\n",
    "        \n",
    "        if kind in {'results', 'timings'}:\n",
    "            single_df = pd.read_csv(fn)            # Reading csv\n",
    "            \n",
    "        elif kind in {'qry_codes'}:\n",
    "            q_codes = np.load(fn)                  # Reading npy\n",
    "            single_df = transform_q_codes(q_codes) # Transformation\n",
    "            \n",
    "        elif kind in {'mod_config'}:\n",
    "            with open(fn, 'r') as f:\n",
    "                cfg = json.load(f)                 # Reading json\n",
    "            single_df = transform_cfg(cfg)         # Transformation\n",
    "        else:\n",
    "            msg = \"\"\"\n",
    "            Did not recognize kind:\\t{}\n",
    "            \"\"\".format(kind)\n",
    "            raise ValueError(msg)\n",
    "        \n",
    "        # Concatenation\n",
    "        head_tuple = ('idx', 'f_idx')\n",
    "        filt_df_fn = df_fns[df_fns[column]==fn]\n",
    "        filt_df_fn = filt_df_fn[list(head_tuple)]\n",
    "\n",
    "        for idx, f_idx in filt_df_fn.itertuples(index=False, name=None):\n",
    "            tmp = add_multindex(single_df, idx, f_idx)\n",
    "            df = pd.concat([df, tmp], sort=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runner = load_or_make_runner(idx=1, kind='RunExp', root_dir=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.aggregate_outputs(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = runner.qry_codes\n",
    "mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.load_output('qry_codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['elia'] = 'cool'\n",
    "df2['elia'] = 'cool'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:] = np.nan\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df,df2], sort=False)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Collect Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_outputs(df_fns, kind='results').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_outputs(df_fns, kind='timings').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_outputs(df_fns, kind='qry_codes').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aggregate_outputs(df_fns, kind='mod_config')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = df.groupby(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,g in gb:\n",
    "    print(n)\n",
    "    print(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:homework]",
   "language": "python",
   "name": "conda-env-homework-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

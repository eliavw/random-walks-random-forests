{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "from os.path import dirname\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom imports\n",
    "\n",
    "root_dir = dirname(dirname(os.getcwd()))\n",
    "src_dir = os.path.join(root_dir, 'src')\n",
    "resc_dir = os.path.join(root_dir, 'resc')\n",
    "libs_dir = os.path.join(root_dir, 'resc')\n",
    "data_dir = os.path.join(resc_dir, 'data')\n",
    "tidy_dir = os.path.join(data_dir, 'tidy')\n",
    "\n",
    "sys.path.append(libs_dir)\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from exp.runner.RunMercs import RunMercs \n",
    "from exp.runner.RunExp import RunExp\n",
    "\n",
    "from exp.utils import filesystem as fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Script\n",
    "\n",
    "Here I just try to achieve what I want, by any means required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_single_csv(config, dataset):\n",
    "    config['io']['dirs']['raw_dataset'] = fs.make_dname(name=dataset, parent_dir=config['io']['dirs']['raw'])\n",
    "    config['io']['dirs']['data_dataset'] = fs.make_dname(name=dataset, parent_dir=config['io']['dirs']['input_data'])\n",
    "    \n",
    "    config['io']['file']['raw'] = fs.make_fname(name=dataset,\n",
    "                                                extension='csv',\n",
    "                                                dname=config['io']['dirs']['raw_dataset'])\n",
    "    \n",
    "    # Joining test, valid and train\n",
    "    fnames = os.listdir(config['io']['dirs']['raw_dataset'])\n",
    "    fnames = [os.path.join(config['io']['dirs']['raw_dataset'],f)\n",
    "              for f in fnames \n",
    "              if ('train' in f or 'test' in f or 'valid' in f)]\n",
    "\n",
    "    dfs = [pd.read_csv(f, header=None) for f in fnames] \n",
    "    \n",
    "    # Join \n",
    "    df_all=pd.concat(dfs)\n",
    "    \n",
    "    # Drop constant columns (These for sure need to go.)\n",
    "    df_all = drop_constant_columns(df_all)\n",
    "    \n",
    "    # Save\n",
    "    df_all.to_csv(config['io']['file']['raw'], header=None, index=False)\n",
    "    \n",
    "    msg = \"\"\"\n",
    "    Done building single csv for dataset:  {}\n",
    "    \"\"\".format(dataset)\n",
    "    #print(msg)\n",
    "    return msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_constant_columns(df):\n",
    "    for col in df:\n",
    "        if df[col].nunique() < 2:\n",
    "            df = df.drop([col], axis=1)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_in_folds(config, dataset, **kwargs):\n",
    "    \n",
    "    config['io']['dirs']['raw_dataset'] = fs.make_dname(name=dataset, parent_dir=config['io']['dirs']['raw'])\n",
    "    config['io']['dirs']['data_dataset'] = fs.make_dname(name=dataset, parent_dir=config['io']['dirs']['input_data'])\n",
    "    \n",
    "    fs.ensure_dir(config['io']['dirs']['data_dataset'])\n",
    "    \n",
    "    config['io']['file']['raw'] = fs.make_fname(name=dataset,\n",
    "                                                extension='csv',\n",
    "                                                dname=config['io']['dirs']['raw_dataset'])\n",
    "    \n",
    "    fname = config['io']['file']['raw']\n",
    "    X = pd.read_csv(fname, header=None)\n",
    "\n",
    "    kf = KFold(**kwargs)\n",
    "\n",
    "    for f_idx, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        dfs = {'Train': X.iloc[train_idx, :],\n",
    "               'Test':  X.iloc[test_idx, :]}\n",
    "\n",
    "        for mode in ['Train', 'Test']:\n",
    "            msg = [mode, fs.gen_appendix(f_idx, kind='fold')]\n",
    "            fold_fname = fs.insert_msg_in_fname(fname, msg)\n",
    "            fold_fname = fs.alter_directory_fname(fold_fname, config['io']['dirs']['data_dataset'])\n",
    "\n",
    "            dfs[mode].to_csv(fold_fname, header=None, index=False)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_constant_cols(directory):\n",
    "    \n",
    "    ds_fnames = [os.path.join(directory, f) for f in os.listdir(directory)\n",
    "                   if 'bayesfusion' not in f]\n",
    "    \n",
    "    ds_train_fnames = [os.path.join(directory, f) for f in os.listdir(directory)\n",
    "                       if 'Train' in f\n",
    "                       if 'bayesfusion' not in f]\n",
    "    \n",
    "    cte_cols = []\n",
    "    \n",
    "    # Detect constant colums\n",
    "    for ds_fn in ds_train_fnames:\n",
    "        # Read\n",
    "        df = pd.read_csv(ds_fn, header=None)\n",
    "        \n",
    "        cte_cols_here = [c for c in df if df[c].nunique() < 2]\n",
    "        cte_cols.extend(cte_cols_here)\n",
    "        \n",
    "        del df\n",
    "        \n",
    "    cte_cols = list(set(cte_cols))\n",
    "    \n",
    "    print(cte_cols)\n",
    "    \n",
    "    # Remove these cols everywhere\n",
    "    for ds_fn in ds_fnames:\n",
    "        df = pd.read_csv(ds_fn, header=None)\n",
    "        for col in cte_cols:\n",
    "            df = df.drop([col], axis=1)\n",
    "            \n",
    "        df.to_csv(ds_fn, header=None, index=False)\n",
    "        del df\n",
    "        \n",
    "    msg = \"\"\"\n",
    "    Finished directory: {}\n",
    "    \"\"\".format(directory)\n",
    "    #print(msg)\n",
    "    \n",
    "    return msg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining CSVs\n",
    "\n",
    "Probably I need do this better and use methods from the filesystem file in exp. (i.e. collect_files_from_folder). But for now, this seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['io'] = {}\n",
    "config['io']['dirs']={}\n",
    "config['io']['file']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config['io']['dirs']['data'] = data_dir\n",
    "config['io']['dirs']['raw'] = fs.make_dname(name='raw', parent_dir=config['io']['dirs']['data'])\n",
    "config['io']['dirs']['input_data'] = fs.make_dname(name='tidy', parent_dir=config['io']['dirs']['data'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "datasets = os.listdir(config['io']['dirs']['raw'])\n",
    "datasets.sort()\n",
    "\n",
    "for ds in datasets:\n",
    "    build_single_csv(config, ds)\n",
    "    msg = \"\"\"\n",
    "    Done building dataset: {}\n",
    "    \"\"\".format(ds)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = os.listdir(config['io']['dirs']['raw'])\n",
    "datasets.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=6)(delayed(build_single_csv)(config, ds)\n",
    "                   for ds in datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in folds\n",
    "\n",
    "Now we focus on creating the different folds."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "datasets = os.listdir(config['io']['dirs']['raw'])\n",
    "datasets.sort()\n",
    "for ds in datasets:\n",
    "    split_in_folds(config, ds, n_splits=10, random_state=997, shuffle=True)\n",
    "    msg = \"\"\"\n",
    "    Done splitting dataset: {}\n",
    "    \"\"\".format(ds)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "datasets = os.listdir(config['io']['dirs']['raw'])\n",
    "datasets.sort()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Parallel(n_jobs=4)(delayed(split_in_folds)(config, ds, n_splits=10, random_state=997, shuffle=True)\n",
    "                   for ds in datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for constant columns in training data\n",
    "\n",
    "These are not accepted in Bayesian Networks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/accidents',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/ad',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/adult',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/baudio',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/bbc',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/bnetflix',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/book',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/c20ng',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/cr52',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/cwebkb',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/dna',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/jester',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/kdd',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/kosarek',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/msnbc',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/msweb',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/nltcs',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/plants',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/pumsb_star',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/tmovie',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/tretail',\n",
       " '/cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/voting']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = os.listdir(tidy_dir)\n",
    "datasets.sort()\n",
    "ds_dirs = [os.path.join(tidy_dir, ds) for ds in datasets]\n",
    "ds_dirs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/accidents\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/ad\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/adult\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/baudio\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/bbc\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/bnetflix\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/book\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/c20ng\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/cr52\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/cwebkb\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/dna\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/jester\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/kdd\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/kosarek\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/msnbc\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/msweb\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/nltcs\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/plants\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/pumsb_star\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/tmovie\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/tretail\\n    ',\n",
       " '\\n    Finished directory: /cw/dtailocal/Dropbox/Files/KUL/research/codebases/homework/resc/data/tidy/voting\\n    ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=6)(delayed(detect_constant_cols)(ds_dir) for ds_dir in ds_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesfusionize\n",
    "\n",
    "Bayesfusion needs headers.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_modify_write(in_fname):\n",
    "    \n",
    "    if 'bayesfusion' in in_fname:\n",
    "        return\n",
    "    elif '.csv' not in in_fname:\n",
    "        return\n",
    "    else:\n",
    "        # Read\n",
    "        df = pd.read_csv(in_fname, header=None)\n",
    "        \n",
    "        # Modify\n",
    "        bf_columns = [\"att_{}\".format(x) for x in df.columns.values]\n",
    "        df.columns = bf_columns\n",
    "        \n",
    "        # Write\n",
    "        base, ext = os.path.splitext(in_fname)\n",
    "        out_fname = base+\"_bayesfusion\"+ext\n",
    "        df.to_csv(out_fname, index=False)\n",
    "        \n",
    "        msg = \"\"\"\n",
    "        Succesful modification of file: {}\n",
    "        Results written to: {}\n",
    "        \"\"\".format(in_fname, out_fname)\n",
    "        #print(msg)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bayesfusionize_dir(directory):\n",
    "    ds_fnames = [os.path.join(directory, x) for x in os.listdir(directory)]\n",
    "    ds_fnames.sort()\n",
    "    for f in ds_fnames:\n",
    "        read_modify_write(f)\n",
    "    return \"Ready for Bayesfusion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir',\n",
       " 'Yessir']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Parallel(n_jobs=6)(delayed(bayesfusionize_dir)(ds) for ds in ds_dirs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
